clusters source, target

source.bootstrap.servers = srcKafka1:10091
target.bootstrap.servers = destKafka1:11091

offset.storage.replication.factor= 1
status.storage.replication.factor= 1
config.storage.replication.factor= 1
replication.factor= 1
source.cluster.alias =
replication.policy.separator =

topics = .*
groups = .*
emit.checkpoints.interval.seconds = 10
sync.group.offsets.interval.seconds = 20
---%<---

source->target.sync.group.offsets.enabled = true
source->target.enabled = true

key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter

producer.override.key.converter=org.apache.kafka.connect.json.JsonConverter
producer.override.value.converter=org.apache.kafka.connect.json.JsonConverter

consumer.override.key.converter=org.apache.kafka.connect.json.JsonConverter
consumer.override.value.converter=org.apache.kafka.connect.json.JsonConverter


# Just for testing
#source->target.transforms=Hoist
#source->target.transforms.Hoist.type=org.apache.kafka.connect.transforms.HoistField$Value
#source->target.transforms.Hoist.field=line
#source->target.transforms.Cast.type=org.apache.kafka.connect.transforms.Cast$Value
#source->target.transforms.Cast.spec=bytes
#source->target.transforms.InsertSource1.type=org.apache.kafka.connect.transforms.InsertField$Value
#source->target.transforms.InsertSource1.static.field=test_inser
#source->target.transforms.InsertSource1.static.value=test_value
